{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598b0ade",
   "metadata": {},
   "source": [
    "# Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d240c",
   "metadata": {},
   "source": [
    "When the true relationship between a predictor and the target is non‑monotonic / piece‑wise, a strictly linear model can fail badly. Converting the feature into categorical “bins” lets the same linear algorithm approximate the step‑function without switching to a more complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa6c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea8395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic data: a STEP‑WISE relationship\n",
    "# x in [0,100]\n",
    "# P(y=1) follows a \"bucket\" profile\n",
    "\n",
    "n = 12000\n",
    "\n",
    "x = np.random.uniform(0, 100, n)\n",
    "\n",
    "# latent step‑wise probabilities\n",
    "p = np.select(\n",
    "        [x < 20, x < 40, x < 60, x < 80, x <= 100],\n",
    "        [0.10,   0.30,   0.70,   0.30,   0.10])\n",
    "y = np.random.binomial(1, p)\n",
    "\n",
    "df = pd.DataFrame({'x': x, 'y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4603f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, \n",
    "            y + np.random.normal(0, .01, n), \n",
    "            alpha=0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc95ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of explicitly doing the Train/Test split\n",
    "\n",
    "idx = np.random.permutation(n)\n",
    "\n",
    "train, test = idx[:int(.8*n)], idx[int(.8*n):]\n",
    "\n",
    "x_train, y_train = df.loc[train, ['x']], df.loc[train, 'y']\n",
    "x_test,  y_test  = df.loc[test,  ['x']], df.loc[test,  'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a7ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: plain LogisticRegression on raw numeric x\n",
    "\n",
    "pipe_raw = Pipeline([\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "]).fit(x_train, y_train)\n",
    "\n",
    "auc_raw = roc_auc_score(y_test, pipe_raw.predict_proba(x_test)[:,1])\n",
    "\n",
    "print(f\"Plain linear model, ROC AUC = {auc_raw:.3f}\")\n",
    "\n",
    "print('Classification report: ')\n",
    "print(classification_report(y_test, pipe_raw.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ac011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binned: cut x into 5 pre‑defined buckets, then one‑hot encode + LR\n",
    "# Use same cut‑points as in the data‑generating process, but in practice determine these via EDA\n",
    "\n",
    "bins = [0, 20, 40, 60, 80, 100]\n",
    "\n",
    "x_train['x_bin'] = pd.cut(x_train['x'], bins=bins, include_lowest=True)\n",
    "x_test['x_bin'] = pd.cut(x_test ['x'], bins=bins, include_lowest=True)\n",
    "\n",
    "ohe = ColumnTransformer(\n",
    "        [('cat', OneHotEncoder(drop='first'), ['x_bin'])],\n",
    "        remainder='drop')\n",
    "\n",
    "pipe_bin = Pipeline([\n",
    "    ('ohe', ohe),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "]).fit(x_train, y_train)\n",
    "\n",
    "auc_bin = roc_auc_score(y_test, pipe_bin.predict_proba(x_test)[:,1])\n",
    "print(f\"Binned feature model, ROC AUC = {auc_bin:.3f}\")\n",
    "\n",
    "print('Classification report: ')\n",
    "print(classification_report(y_test, pipe_bin.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b30c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "\n",
    "# Predictions across a range of x\n",
    "xx  = np.linspace(0, 100, 500)\n",
    "pp_raw = pipe_raw.predict_proba(xx.reshape(-1,1))[:,1]\n",
    "\n",
    "# Build a tiny DF to pass through the binning & LogReg pipeline\n",
    "tmp = pd.DataFrame({'x': xx})\n",
    "tmp['x_bin'] = pd.cut(tmp['x'], bins=bins, include_lowest=True)#, right=False)\n",
    "pp_bin = pipe_bin.predict_proba(tmp[['x_bin']])[:,1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6,3))\n",
    "\n",
    "plt.plot(xx, pp_raw, label='Raw LR (linear)')\n",
    "plt.plot(xx, pp_bin, label='Binned LR')\n",
    "plt.scatter(x, y + np.random.normal(0, .01, n), alpha=.03)\n",
    "\n",
    "plt.ylabel('Predicted P(y=1)')\n",
    "plt.xlabel('x')\n",
    "plt.ylim(-.05,1.05)\n",
    "plt.title('How binning lets a linear model mimic a step function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb44268",
   "metadata": {},
   "source": [
    "## Results:\n",
    "\n",
    "| Model         | Feature representation                           | Can mimic step‑wise target?                | Test ROC‑AUC |\n",
    "| ------------- | ------------------------------------------------ | ------------------------------------------ | ------------ |\n",
    "| Plain LR  | 1 numeric coefficient                            | No — forces a single sigmoid trend         | 0.50         |\n",
    "| Binned LR | 4 dummy coefficients (5 buckets minus reference) | Yes — assigns its own log‑odds to each bin | 0.76     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0985f6",
   "metadata": {},
   "source": [
    "The linear algorithm itself did not change.\n",
    "\n",
    "By discretising x into bins that align with real shifts, the model has enough flexibility to capture the non‑linear structure while keeping its interpretability and training speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15c816",
   "metadata": {},
   "source": [
    "* Binning:\n",
    "  * Helps with piece‑wise or plateau effects (marketing spend thresholds, credit‑score bands, age brackets).\n",
    "  * Robust to outliers (extreme values map to a common \"tail\" bin).\n",
    "  * Monotonic‑constraint preparation for scorecards / WOE encoding in credit‑risk models.\n",
    "  * Explainability: \"Applicants earning 40,000‑60,000 have 3x default risk' is easier to tell a stakeholder than “slope = 0.08 log‑odds per 1000\".\n",
    "  * Conversely, tree‑based models already split features internally; careless binning there can harm resolution. Always profile the feature and the algorithm before deciding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
