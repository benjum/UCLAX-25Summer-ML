{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5c75b1-6b15-49c2-869b-6af409ef317e",
   "metadata": {},
   "source": [
    "# Revisiting our Classification Example from Week01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87bb76-8931-4c36-90ec-2c5c852da999",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352cd2d4-32c1-4ae8-8c6f-35a489becbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a73018-67a9-4e0d-8e3d-4352d7b47c9f",
   "metadata": {},
   "source": [
    "Side note:\n",
    "* I will be posting data files and shared notebooks in a GitHub repository: https://github.com/benjum/UCLAX-25Summer-ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc56b2-1e6e-428e-a19f-514a29452f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/benjum/UCLAX-25Summer-ML/main/Data/gdp-vs-lifesatisfaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77a048-4d33-436b-965c-f2020d34d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d949bd-170a-47ce-84cc-aebc4add7a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6718eaf-69aa-4535-a1f1-81ebb07eb299",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1e248-cd18-491f-a85d-d1c45c7283f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the appropriate elements to x and y\n",
    "x = data[:,1]\n",
    "y = data[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45077345-5159-4b07-8634-f685b0e0af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scatter plot\n",
    "\n",
    "plt.plot(x,y,'ko')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f3c05c-fe13-4355-ba97-5811e7ad4745",
   "metadata": {},
   "source": [
    "## Scikit-learn\n",
    "\n",
    "* Scikit-Learn docs: https://scikit-learn.org/stable/index.html\n",
    "* K-Nearest Neighbors Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "* Logistic Regression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31d43b7-51d4-4e0d-8a54-ad089a6fb38d",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b24ee89-759b-4378-adaf-eafbe82f5a35",
   "metadata": {},
   "source": [
    "Classification is appropriate when the target variable has a discrete set of values, not a continuous set.  In order to illustrate classification with this data, I am going to convert it into True/False (1/0) values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda42c2-1004-4609-b5c1-c52646b29fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7122ec-a5b9-4e99-b344-06281dae38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y >= 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e168f18-a40f-4d45-b684-aa76813cffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1 if (i >= 6.5) else 0 for i in y ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d16d93f-3a89-4877-89d1-dd832c484175",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319c458-7464-4aad-bc38-75acabcf1ee3",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b2dec-22f3-48a1-83ca-c5bcb6054b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e879e8-68be-4a5f-85ba-5b73047cb5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier\n",
    "model = sklearn.neighbors.KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d6565f-6d31-4d40-a5ad-272ff76beea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape our data to be 2D rather than 1D\n",
    "# (only needed if our feature array starts out as 1D)\n",
    "x = x.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e17ae-bc55-4eb7-a5d0-0b0bf64c24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed8028c-ac18-425e-96bd-597125ba5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "x_test = [[25000]]\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f6cf3-02f7-4f19-b582-e4aff0befdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize what the predictions are for this model\n",
    "\n",
    "plt.plot(x, y, 'ko')\n",
    "\n",
    "x_new = np.linspace(8000,58000,100000)\n",
    "x_new = x_new.reshape(-1,1)\n",
    "y_pred = model.predict(x_new)\n",
    "plt.plot(x_new, y_pred)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e4422e-d9a1-4678-bbf2-817d3b35c157",
   "metadata": {},
   "source": [
    "## Classification's performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6460cd8-3f12-46e3-80ed-05738db05567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab31c6-40b4-421a-b567-0b96fb2a45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the model correctly classifies i points and misclassifies j points out of k total\n",
    "# the score should be i/k\n",
    "28/29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ef6f4-bef6-4cca-8ca9-f7cf134536ad",
   "metadata": {},
   "source": [
    "The above is termed the accuracy.  By default, each algorithm's \"score\" method may be a little different:\n",
    "* [`score` for KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8960befb-8cdf-48f9-9f27-5d1773314586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that when calculating the precision and recall here, if your classes are not 0/1\n",
    "# you will need to specify what class is positive vs negative (the \"pos_label\")\n",
    "\n",
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y, model.predict(x)):.2%}\")\n",
    "print(f\"Precision: {sklearn.metrics.precision_score(y, model.predict(x), pos_label=1):.2%}\")\n",
    "print(f\"Recall: {sklearn.metrics.recall_score(y, model.predict(x), pos_label=1):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02151ba7-b88e-49bf-8b27-2c0be15358a5",
   "metadata": {},
   "source": [
    "You can get more information on the model performance with a confusion matrix. \n",
    "\n",
    "In the case of binary classification, the confusion matrix shows true negatives, true positives, false positives, and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be59a97-5450-4809-99ab-8aa7e5574e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e35ed-ecc4-43a3-a4cd-fbdb3be6c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173bdb01-c659-44ee-9fb1-5fdce89f3832",
   "metadata": {},
   "source": [
    "And with the classification report, we can see the precision and recall (and other scores) broken down according to class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03097f6b-f62c-4aa8-ad3f-c40db807798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8cd1a-93ff-462e-a909-0c915fbfe43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e2f25-9075-4f5c-b47f-3c50f1688c69",
   "metadata": {},
   "source": [
    "We discussed precision and recall for binary classification, but for multi-class classification problems, these metrics can be computed in slightly different ways depending on how one does averaging. \n",
    "\n",
    "A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally), a weighted average will compute the metric independently for each class but then additionally take into account the support when calculating the overall average, and a micro-average will aggregate the contributions of all classes to compute the average metric. \n",
    "\n",
    "In a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fbaf61-181f-49d4-99e9-f0b41c050b0b",
   "metadata": {},
   "source": [
    "# Classification based on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc7bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier with logistic regression\n",
    "model = sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154c994-5e86-4600-946e-de00601da141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e43f1e-ade6-473e-9d7d-8fee7a438dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize what the predictions are for this model\n",
    "\n",
    "plt.plot(x, y, 'ko')\n",
    "\n",
    "x_new = np.linspace(8000,58000,100000)\n",
    "x_new = x_new.reshape(-1,1)\n",
    "y_pred = model.predict(x_new)\n",
    "plt.plot(x_new, y_pred)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb33733-f709-44ae-9c2b-c4518c559274",
   "metadata": {},
   "source": [
    "Note what is different about the above prediction curve relative to that for KNN Classification.  Can you make them more similar?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf752c-0663-44a7-8c1a-21edf976909d",
   "metadata": {},
   "source": [
    "## Learned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d47ea9-4d38-4014-a55c-109fbb8e5409",
   "metadata": {},
   "source": [
    "With logistic regression, the optimal values for coefficients of a specific model equation have been learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec40fbe-6ca9-4b8b-a5ac-8014de202c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this model, we can actually retrieve parameters for our model equation\n",
    "print(model.coef_, model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece97b61-84c1-4a46-91af-5e1ebeb9d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc078ce-c249-4731-8de0-f6e15d55d4ce",
   "metadata": {},
   "source": [
    "What's the `intercept_` and `coef_` for a logistic model?\n",
    "\n",
    "$$f(x) = \\frac{1}{1+e^{-(a_0 + a_1 x)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7418b-29a1-4c0b-9203-b3b87117c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize what the predictions are for this model\n",
    "\n",
    "plt.plot(x,y,'ko')\n",
    "\n",
    "x_new = np.linspace(8000,58000,100000)\n",
    "x_new = x_new.reshape(-1,1)\n",
    "\n",
    "# the predicted y values are now from a model equation, \n",
    "# not from results of calling the predict function\n",
    "y_model = 1 / (1 + np.exp(-(model.intercept_ + model.coef_ * x_new)))\n",
    "\n",
    "plt.plot(x_new, y_model)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2148168-e619-46ca-a818-65fcc76c6a56",
   "metadata": {},
   "source": [
    "The learned model $f(x)$ gives us a probability of belonging to the \"positive\" class, and we can take $f(x) > 0.5$, for example, to be a threshold for classifying as one class vs another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed10a689-039e-45bb-86ff-d9edd8b7a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize what the predictions are for this model\n",
    "\n",
    "plt.plot(x,y,'ko')\n",
    "\n",
    "x_new = np.linspace(8000,58000,100000)\n",
    "x_new = x_new.reshape(-1,1)\n",
    "\n",
    "# the predicted y values are now from a model equation, \n",
    "# not from results of calling the predict function\n",
    "y_model = 1 / (1 + np.exp(-(model.intercept_ + model.coef_ * x_new)))\n",
    "\n",
    "plt.plot(x_new, y_model)\n",
    "\n",
    "plt.axhline(0.5,color='r',linestyle='--')\n",
    "\n",
    "x_new = np.linspace(8000,58000,100000)\n",
    "x_new = x_new.reshape(-1,1)\n",
    "y_pred = model.predict(x_new)\n",
    "plt.plot(x_new, y_pred)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03593703-dc2f-40e6-8014-95dbbfdab485",
   "metadata": {},
   "source": [
    "## Classification's performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ae0be-5e6d-4d4b-8172-dcbe53ded867",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbd3d60-8557-48e0-8482-f284d27d51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the model correctly classifies i points and misclassifies j points out of k total\n",
    "# the score should be i/k\n",
    "27/29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525205b0-305c-4be4-bcf6-97a5764eb468",
   "metadata": {},
   "source": [
    "The above is termed the accuracy.  By default, each algorithm's \"score\" method may be a little different:\n",
    "* [`score` for KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81c7c86-637e-4811-8d88-eff5d469ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that when calculating the precision and recall here, if your classes are not 0/1\n",
    "# you will need to specify what class is positive vs negative (the \"pos_label\")\n",
    "\n",
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y, model.predict(x)):.2%}\")\n",
    "print(f\"Precision: {sklearn.metrics.precision_score(y, model.predict(x), pos_label=1):.2%}\")\n",
    "print(f\"Recall: {sklearn.metrics.recall_score(y, model.predict(x), pos_label=1):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e2e08-28b1-42ab-8671-525332cc021d",
   "metadata": {},
   "source": [
    "You can get more information on the model performance with a confusion matrix. \n",
    "\n",
    "In the case of binary classification, the confusion matrix shows true negatives, true positives, false positives, and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b534b-5a46-4aad-97fe-f18b57b43675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555d2a4-5898-48e9-be08-22344215f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b98f4-52fc-4a01-b384-5fb59d0daf03",
   "metadata": {},
   "source": [
    "And with the classification report, we can see the precision and recall (and other scores) broken down according to class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e6dff-0ea7-4b22-9979-8d31cf64721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c090a5-569a-440a-912a-a3ec21001e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e61f4-5717-4913-b3d5-1e211eeee25c",
   "metadata": {},
   "source": [
    "## Brining in last week's content:  Test/Train Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd030c37-2457-4c3b-92a3-6bbabd214fc2",
   "metadata": {},
   "source": [
    "With logistic regression, the optimal values for coefficients of a specific model equation have been learned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac8fe5c-bf58-4750-bda8-657b49b60a32",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f04560-1d2c-48cf-89a5-b1d22f43c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2843d85f-aab0-437f-92aa-cc029b0c48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8be3e-9ee7-4bb3-b709-e0f7c1f3e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier with logistic regression\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "# Train the model with x_train and y_train\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "# Visualize what the predictions are for this model\n",
    "\n",
    "plt.plot(x_train, y_train, 'ko')\n",
    "plt.plot(x_test, y_test, 'bo')\n",
    "\n",
    "x_new = np.linspace(8000,58000,100000)\n",
    "x_new = x_new.reshape(-1,1)\n",
    "y_pred = model.predict(x_new)\n",
    "plt.plot(x_new, y_pred)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Assess performance with x_test and y_test\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e27524b-38e6-4e60-974e-7afbf022a912",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2211c-bfb5-486a-819a-cbca266f3c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier with logistic regression\n",
    "model = sklearn.linear_model.LogisticRegression(solver = 'newton-cholesky', \n",
    "                                                C = 1e-10)\n",
    "\n",
    "# Train the model with x_train and y_train\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "# Visualize what the predictions are for this model\n",
    "\n",
    "plt.plot(x_train, y_train, 'ko')\n",
    "plt.plot(x_test, y_test, 'bo')\n",
    "\n",
    "x_new = np.linspace(8000,58000,100000)\n",
    "x_new = x_new.reshape(-1,1)\n",
    "y_pred = model.predict(x_new)\n",
    "plt.plot(x_new, y_pred)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Assess performance with x_test and y_test\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bd8ff8-1ded-4b37-853c-5b920e534c71",
   "metadata": {},
   "source": [
    "## Visualizing the effect of regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f535da-9c0c-4a71-ac83-f475cc596ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc0271-9dbe-4640-a03b-3d78d25f7998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2models(c = 0):\n",
    "    model0 = sklearn.linear_model.LogisticRegression()\n",
    "    model1 = sklearn.linear_model.LogisticRegression(solver = 'newton-cholesky', \n",
    "                                                    C = 10**(-c))\n",
    "    \n",
    "    model0.fit(x_train,y_train)\n",
    "    model1.fit(x_train,y_train)\n",
    "    \n",
    "    # Visualize what the predictions are for this model\n",
    "    \n",
    "    plt.plot(x_train,y_train,'ko')\n",
    "    plt.plot(x_test,y_test,'bo')\n",
    "    \n",
    "    x_new = np.linspace(8000,58000,100000)\n",
    "    x_new = x_new.reshape(-1,1)\n",
    "    \n",
    "    # the predicted y values are now from a model equation, \n",
    "    # not from results of calling the predict function\n",
    "    y_model0 = 1 / (1 + np.exp(-(model0.intercept_ + model0.coef_ * x_new)))\n",
    "    y_model1 = 1 / (1 + np.exp(-(model1.intercept_ + model1.coef_ * x_new)))\n",
    "    \n",
    "    plt.plot(x_new, y_model0, 'r')\n",
    "    plt.plot(x_new, y_model1, 'g')\n",
    "    \n",
    "    plt.axhline(0.5,color='r',linestyle='--')\n",
    "    \n",
    "    x_new = np.linspace(8000,58000,100000)\n",
    "    x_new = x_new.reshape(-1,1)\n",
    "    y_pred = model1.predict(x_new)\n",
    "    plt.plot(x_new, y_pred)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "ipywidgets.interact(plot2models, c=(1,10));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
